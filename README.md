# Copyright-Safe LLM Agent

This project explores methods to detect and mitigate potential copyright infringements in the outputs of large language models (LLMs). It includes:

- A **Prompting Agent** to systematically query LLMs using varied strategies
- An **Evaluator Agent** to analyze responses for copyright risks using multiple similarity metrics

The goal is to build a framework for safer, more accountable LLM outputsâ€”particularly useful in compliance, publishing, and AI ethics contexts.

ðŸ”¬ *Work in progress â€“ experimental setup and results are under development.*

## Project Structure

- `Prompting_Agent.ipynb`: Handles multi-strategy LLM prompting
- `Evaluator_Agent.ipynb`: Measures textual overlap and semantic similarity
- `FinalReport_TerminationProject_mfasching.pdf`: Conceptual overview and project report

## License

MIT License
